"""
LLM ëª¨ë“ˆ - RAGë¥¼ ì ìš©í•œ ì˜ì•½í’ˆ ì •ë³´ ì§ˆì˜ì‘ë‹µ
"""

import json
import os
from typing import Optional
from llama_index.core import (
    Document,
    VectorStoreIndex,
    StorageContext,
    Settings
)
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.postprocessor import SimilarityPostprocessor
from llama_index.core.response_synthesizers import get_response_synthesizer
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from dotenv import load_dotenv

load_dotenv()

class LLMModule:
    def __init__(self, e_data_path="e_data.json", n_data_path="n_data.json"):
        """
        LLM RAG ëª¨ë“ˆ ì´ˆê¸°í™”
        
        Args:
            e_data_path: ì˜ì•½í’ˆ í—ˆê°€ì •ë³´ JSON íŒŒì¼ ê²½ë¡œ
            n_data_path: ì˜ì•½í’ˆ ê°œìš”ì •ë³´ JSON íŒŒì¼ ê²½ë¡œ
        """
        print("ğŸ¤– LLM ëª¨ë“ˆì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
        
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.e_data_path = e_data_path
        self.n_data_path = n_data_path
        
        # OpenAI ì„¤ì •
        os.environ["OPENAI_API_KEY"] = self.api_key
        
        # LLM ì„¤ì •
        self.llm = OpenAI(
            model="gpt-4o-mini",
            temperature=0.1,
            max_tokens=2000
        )
        
        # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        self.embed_model = OpenAIEmbedding(
            model="text-embedding-3-small",
            embed_batch_size=100
        )
        
        # Settings êµ¬ì„±
        Settings.llm = self.llm
        Settings.embed_model = self.embed_model
        Settings.chunk_size = 1024
        Settings.chunk_overlap = 100
        
        # ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        self.index = None
        self.query_engine = None
        
        # ì¸ë±ìŠ¤ êµ¬ì¶•
        self._build_index()
        
        print("âœ… LLM ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ!")
    
    def _build_index(self):
        """ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶•"""
        index_path = "./medicine_index"
        
        # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„
        if os.path.exists(index_path):
            print("  ğŸ“‚ ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘...")
            from llama_index.core import load_index_from_storage
            storage_context = StorageContext.from_defaults(persist_dir=index_path)
            self.index = load_index_from_storage(storage_context)
        else:
            print("  ğŸ”¨ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ëŠ” ì¤‘...")
            documents = self._load_data()
            
            if documents:
                self.index = VectorStoreIndex.from_documents(
                    documents,
                    show_progress=True
                )
                self.index.storage_context.persist(persist_dir=index_path)
            else:
                print("  âš ï¸ ì˜ì•½í’ˆ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. RAG ì—†ì´ ë™ì‘í•©ë‹ˆë‹¤.")
                return
        
        # ì¿¼ë¦¬ ì—”ì§„ ì„¤ì •
        if self.index:
            self._setup_query_engine()
    
    def _load_data(self):
        """ì˜ì•½í’ˆ ë°ì´í„° ë¡œë“œ"""
        documents = []
        
        # e_data.json ë¡œë“œ
        if os.path.exists(self.e_data_path):
            try:
                with open(self.e_data_path, 'r', encoding='utf-8') as f:
                    e_data = json.load(f)
                    for medicine in e_data.get('medicines', []):
                        text = self._format_medicine_data(medicine, "permit")
                        if text:
                            doc = Document(
                                text=text,
                                metadata={
                                    "source": "permit",
                                    "item_name": medicine.get("itemName", "")[:100]
                                }
                            )
                            documents.append(doc)
            except Exception as e:
                print(f"  âš ï¸ e_data.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # n_data.json ë¡œë“œ
        if os.path.exists(self.n_data_path):
            try:
                with open(self.n_data_path, 'r', encoding='utf-8') as f:
                    n_data = json.load(f)
                    for medicine in n_data.get('medicines', []):
                        text = self._format_medicine_data(medicine, "overview")
                        if text:
                            doc = Document(
                                text=text,
                                metadata={
                                    "source": "overview",
                                    "item_name": (medicine.get("item_name") or 
                                                medicine.get("ITEM_NAME", ""))[:100]
                                }
                            )
                            documents.append(doc)
            except Exception as e:
                print(f"  âš ï¸ n_data.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return documents
    
    def _format_medicine_data(self, medicine, source_type):
        """ì˜ì•½í’ˆ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        text_parts = []
        
        if source_type == "permit":
            # í—ˆê°€ì •ë³´ í¬ë§·
            fields = [
                ("itemName", "ì˜ì•½í’ˆëª…"),
                ("entpName", "ì œì¡°ì‚¬"),
                ("efcyQesitm", "íš¨ëŠ¥íš¨ê³¼"),
                ("useMethodQesitm", "ìš©ë²•ìš©ëŸ‰"),
                ("atpnWarnQesitm", "ì£¼ì˜ì‚¬í•­ ê²½ê³ "),
                ("atpnQesitm", "ì£¼ì˜ì‚¬í•­"),
                ("intrcQesitm", "ìƒí˜¸ì‘ìš©"),
                ("seQesitm", "ë¶€ì‘ìš©"),
                ("depositMethodQesitm", "ë³´ê´€ë°©ë²•")
            ]
            
            for field, label in fields:
                if medicine.get(field):
                    text_parts.append(f"{label}: {medicine[field]}")
        
        else:  # overview
            # ê°œìš”ì •ë³´ í¬ë§·
            fields = [
                (["item_name", "ITEM_NAME"], "ì˜ì•½í’ˆëª…"),
                (["entp_name", "ENTP_NAME"], "ì œì¡°ì‚¬"),
                (["chart", "CHART"], "ì„±ìƒ"),
                (["drug_shape", "DRUG_SHAPE"], "ì˜ì•½í’ˆ ëª¨ì–‘"),
                (["color_class1", "COLOR_CLASS1"], "ìƒ‰ìƒ ì•"),
                (["color_class2", "COLOR_CLASS2"], "ìƒ‰ìƒ ë’¤"),
                (["class_name", "CLASS_NAME"], "ì•½í’ˆ ë¶„ë¥˜"),
                (["etc_otc_name", "ETC_OTC_NAME"], "ì „ë¬¸/ì¼ë°˜")
            ]
            
            for field_names, label in fields:
                for field in field_names:
                    if medicine.get(field):
                        text_parts.append(f"{label}: {medicine[field]}")
                        break
        
        return "\n".join(text_parts) if text_parts else None
    
    def _setup_query_engine(self):
        """ì¿¼ë¦¬ ì—”ì§„ ì„¤ì •"""
        retriever = VectorIndexRetriever(
            index=self.index,
            similarity_top_k=10,
        )
        
        response_synthesizer = get_response_synthesizer(
            response_mode="tree_summarize",
        )
        
        self.query_engine = RetrieverQueryEngine(
            retriever=retriever,
            response_synthesizer=response_synthesizer,
            node_postprocessors=[
                SimilarityPostprocessor(similarity_cutoff=0.3)
            ],
        )
    
    def query(self, question: str, ocr_context: Optional[str] = None):
        """
        ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            ocr_context: OCRë¡œ ì¶”ì¶œëœ ì•½í’ˆ ì •ë³´ (ìˆëŠ” ê²½ìš°)
            
        Returns:
            ìƒì„±ëœ ë‹µë³€
        """
        # ì§ˆë¬¸ í–¥ìƒ
        enhanced_question = self._enhance_question(question, ocr_context)
        
        print(f"ğŸ’­ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: '{question[:50]}...'")
        if ocr_context:
            print("  ğŸ“„ OCR ì»¨í…ìŠ¤íŠ¸ í¬í•¨")
        
        try:
            if self.query_engine:
                # RAGë¥¼ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±
                response = self.query_engine.query(enhanced_question)
                answer = str(response)
            else:
                # RAG ì—†ì´ ì§ì ‘ LLM ì‚¬ìš©
                prompt = enhanced_question
                response = self.llm.complete(prompt)
                answer = str(response)
            
            if not answer or not answer.strip():
                answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return answer
            
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _enhance_question(self, question: str, ocr_context: Optional[str] = None):
        """ì§ˆë¬¸ í–¥ìƒ -"""
        enhanced = "ì˜ì•½í’ˆ ì •ë³´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.\n\n"
        
        # OCR ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if ocr_context:
            enhanced += f"ì‚¬ìš©ìê°€ ì…ë ¥ìœ¼ë¡œ ë„£ì€ ì˜ì•½í’ˆ ì •ë³´ì…ë‹ˆë‹¤ : {ocr_context}\n\n"
        
        enhanced += f"ì§ˆë¬¸: {question}\n\n"
        enhanced += "ë‹µë³€ì€ ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì‹œê³ , ì¤‘ìš”í•œ ì£¼ì˜ì‚¬í•­ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•´ì£¼ì„¸ìš”. í•µì‹¬ ìš”ì ì„ ë¨¼ì € ì´ì•¼ê¸°í•˜ê³ , ê°€ê¸‰ì  ë¬¼ì–´ë³¸ ì§ˆë¬¸ì˜ í•µì‹¬ ë‚´ìš©ë§Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. ì§ˆë¬¸ì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ë‚´ìš©ì€ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”."
        
        # íŠ¹ì • í‚¤ì›Œë“œì— ë”°ë¥¸ ì¶”ê°€ ì§€ì‹œ
        if "ë¶€ì‘ìš©" in question:
            enhanced += " ë¶€ì‘ìš©ê³¼ ì´ìƒë°˜ì‘ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        elif "ìš©ë²•" in question or "ìš©ëŸ‰" in question:
            enhanced += " ì•Œì•½ì˜ ê²½ìš° ëª‡ ì•Œ ë‹¨ìœ„ë¡œ, ì•¡ì²´ì˜ ê²½ìš° mg ë‹¨ìœ„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì‚¬ìš©ë²• ë˜ëŠ” ìš©ëŸ‰ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        elif "ìƒí˜¸ì‘ìš©" in question or "ê°™ì´" in question:
            enhanced += " ì•½ë¬¼ ìƒí˜¸ì‘ìš©ê³¼ ë³‘ìš© ê¸ˆê¸° ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        
        return enhanced